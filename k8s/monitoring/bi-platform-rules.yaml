apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: bi-platform-alerts
  namespace: business-intelligence
  labels:
    app: bi-platform
    monitoring: enabled
spec:
  groups:
    - name: bi-platform.rules
      interval: 30s
      rules:
        # SLI Recording Rules
        - record: bi_platform:availability_5m
          expr: avg(up{job="bi-platform"})

        - record: bi_platform:latency_p95_5m
          expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="bi-platform"}[5m]))

        - record: bi_platform:latency_p99_5m
          expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{job="bi-platform"}[5m]))

        - record: bi_platform:error_rate_5m
          expr: rate(http_requests_total{job="bi-platform",status=~"5.."}[5m]) / rate(http_requests_total{job="bi-platform"}[5m])

        - record: bi_platform:throughput_5m
          expr: rate(http_requests_total{job="bi-platform"}[5m])

        # Alert Rules
        - alert: HighErrorRate
          expr: bi_platform:error_rate_5m > 0.1
          for: 5m
          labels:
            severity: critical
            team: backend
            service: bi-platform
          annotations:
            summary: "High error rate detected for BI Platform"
            description: "Error rate is {{ $value | humanizePercentage }} which is above the 10% threshold"
            runbook_url: "https://runbook.bi-platform.com/alerts/high-error-rate"

        - alert: HighResponseTime
          expr: bi_platform:latency_p95_5m > 2.0
          for: 5m
          labels:
            severity: critical
            team: backend
            service: bi-platform
          annotations:
            summary: "High response time detected for BI Platform"
            description: "P95 response time is {{ $value }}s which is above the 2s threshold"
            runbook_url: "https://runbook.bi-platform.com/alerts/high-latency"

        - alert: HighCPUUsage
          expr: rate(container_cpu_usage_seconds_total{pod=~"bi-platform-.*"}[5m]) > 0.8
          for: 5m
          labels:
            severity: warning
            team: infrastructure
            service: bi-platform
          annotations:
            summary: "High CPU usage detected for BI Platform"
            description: "CPU usage is {{ $value | humanizePercentage }} which is above the 80% threshold"
            runbook_url: "https://runbook.bi-platform.com/alerts/high-cpu"

        - alert: HighMemoryUsage
          expr: container_memory_usage_bytes{pod=~"bi-platform-.*"} / container_spec_memory_limit_bytes{pod=~"bi-platform-.*"} > 0.8
          for: 5m
          labels:
            severity: warning
            team: infrastructure
            service: bi-platform
          annotations:
            summary: "High memory usage detected for BI Platform"
            description: "Memory usage is {{ $value | humanizePercentage }} which is above the 80% threshold"
            runbook_url: "https://runbook.bi-platform.com/alerts/high-memory"

        - alert: ServiceDown
          expr: up{job="bi-platform"} == 0
          for: 1m
          labels:
            severity: critical
            team: backend
            service: bi-platform
          annotations:
            summary: "BI Platform service is down"
            description: "BI Platform instance {{ $labels.instance }} is down"
            runbook_url: "https://runbook.bi-platform.com/alerts/service-down"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: slo-burn-rate-alerts
  namespace: business-intelligence
  labels:
    app: slo-monitoring
    monitoring: enabled
spec:
  groups:
    - name: slo-burn-rate.rules
      interval: 30s
      rules:
        # SLO Burn Rate Recording Rules
        - record: bi_platform:availability_slo_burn_rate_1h
          expr: (1 - bi_platform:availability_5m) / (1 - 0.999)

        - record: bi_platform:latency_slo_burn_rate_1h
          expr: (bi_platform:latency_p95_5m - 1.0) / 1.0

        - record: bi_platform:error_rate_slo_burn_rate_1h
          expr: bi_platform:error_rate_5m / 0.001

        # Error Budget Alerts
        - alert: ErrorBudgetBurnRate
          expr: bi_platform:error_rate_slo_burn_rate_1h > 10
          for: 2m
          labels:
            severity: critical
            team: backend
            service: bi-platform
            slo_type: error_budget
          annotations:
            summary: "Error budget burning too fast"
            description: "Error budget burn rate is {{ $value }}x normal rate"
            runbook_url: "https://runbook.bi-platform.com/slo/error-budget-critical"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: monitoring-stack-alerts
  namespace: monitoring
  labels:
    app: monitoring-stack
    monitoring: enabled
spec:
  groups:
    - name: monitoring-stack.rules
      interval: 30s
      rules:
        - alert: PrometheusDown
          expr: up{job="prometheus"} == 0
          for: 1m
          labels:
            severity: critical
            team: monitoring
            service: prometheus
          annotations:
            summary: "Prometheus is down"
            description: "Prometheus monitoring system is not responding"

        - alert: GrafanaDown
          expr: up{job="grafana"} == 0
          for: 1m
          labels:
            severity: critical
            team: monitoring
            service: grafana
          annotations:
            summary: "Grafana is down"
            description: "Grafana dashboard system is not responding"

        - alert: AlertManagerDown
          expr: up{job="alertmanager"} == 0
          for: 1m
          labels:
            severity: critical
            team: monitoring
            service: alertmanager
          annotations:
            summary: "AlertManager is down"
            description: "AlertManager notification system is not responding"

        - alert: PrometheusConfigReload
          expr: prometheus_config_last_reload_successful == 0
          for: 1m
          labels:
            severity: warning
            team: monitoring
            service: prometheus
          annotations:
            summary: "Prometheus configuration reload failed"
            description: "Prometheus failed to reload its configuration"